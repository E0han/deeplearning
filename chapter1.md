# Basic Ideas

### 2.1 背景知识

_**机器学习问题 **_包含**回归\(regression\)**与**分类\(classification\)**两大类问题:

**Regression: **对于一个输入x，预测其输出值y,这个y值是根据x连续变化的值.

**Classification:** 事先给定诺干个类别，对于一个输入x，判断其属于哪个类别，即输出一般是离散的。

_**机器学习方法 **_中主要包含**有监督**和**无监督:**

**有监督学习：**对输入的data既包含输入x，又包含x对应的y，即学习数据已经事先给出了正确答案

**无监督学习：** 只有输入x。无监督学习目前一般用于**聚类\(cluster\)**问题，即给定一批数据，根据这批数据的特点，将其分为多个类别。

**神经网络\(neural network\):**

让机器学习，一般需要：

1. 用来解决问题的模型model
2. 学习数据 data
3. 让模型model通过学习数据data学会解决特定问题的**学习算法learn**

![](/assets/import.png)

图中的每个圆圈代表一个个神经元（neuron），其中网络层1中的每个neuron 都与网络层2中的美恶搞neuron相连。每条线上的w都代表权重.

neural network工作时，将前一层网络中的每个neuron值与权重w相乘，传递给下一层网络中的neuron，同时每个neuron都会接受一个**偏移量\(bias\).** 即在图中有:

```
w11*a1 + w12*a2 + w13*a3 + bias1 = b1
w21*a1 + w22*a2 + w23*a3 + bias2 = b2
```

写成矩阵如下:

![](/assets/import.pnghttps:/dn-anything-about-doc.qbox.me/document-uid49570labid2864timestamp1493273775452.png)

这是一个线性方程组，但是神经网络中不仅是有线性方程，回到神经网络模型图中，网络层2中的b1和b2到输出，还需要经历一次非线性运算g,即：

```
g(b1)=h1
g(b2)=h2
```

在神经网络中，将上述的g称作**激活函数\(**Activity Rule**\)，**在实际运用中，有很多激活函数可以选择，本笔记介绍最经典的一种sigmoid激活函数，它的数学形态是:

![](/assets/sigmoid.png)  
显而易见，输入的x值越大，g\(x\)越接近1；输入的x值越小，g\(x\)越接近0

使用非线性运算的理由如下:

在如图所示的**深度学习网络**中：

![](/assets/deep_learning_network.png)

* 网络1和网络2组成的尺寸为2x3的矩阵，网络2和网络3组成的尺寸为3x2的矩阵，由于矩阵乘法的结合型\(见上文\)会合并为一个尺寸为3x3的矩阵
* 只考虑线性运算的部分，比如b1，应用于分类问题:

```
w11*a1+w12*a2 + bias1=b1
```

对于输入的a，如果最后的b大于0，即可以认为a属于b1所代表的类别，else，不属于b1

The diagram for equation of b1 is shown below:

![](/assets/linear_function.png)

Red dots in the diagram represent b1, Green dots less than 0, so they are not belong to b1

如果输入的数据是3维的，那图中的线性方程可以用平面来替代。平面对空间进行划分。但问题便显现了，如果b的分布函数图像如下怎么办?

![](/assets/function_diagram_2.png)

此时就无法使用线性分类去准确地分类，则饮用激励函数使得直线变成曲线:

![](/assets/curve_function.png)

> 非线性激活函数还有其他作用，比如`sigmoid`将输出值的范围限制在0到1之间，使其刚好可以被作为概率来看待。

### 2.2 评价神经网络的效果

##### 2.2.1随机值初始化神经网络参数

神经网络中的网络参数值，包括权重w以及bias偏差值。一种简单的方法是随机设定网络参数值，那么我们所得到的“网络性能”应该是随机情况下的平均值。比如我们要判断一些图片中的字母属于26个字母中的哪一个，如果网络参数值是随机设定的话，那我们得到的识别准确率理论上应该在1/26左右。随机设定参数值当然不可能是我们解决问题的办法，但要学习如何设置“好”的网络参数值来使神经网络正确的工作，我们要先研究一下上面提到的“网络性能”的问题。

我们如何判定一个神经网络是“好”的还是“不好”的呢，即我们用什么来评价一个神经网络的效果呢？

##### 2.2.2 损失函数（Cost Function）的概念

在有监督学习中，由于输入的data包含了输入x值和正确的输出y值，简单的方法就是比较神经网络的输出h值和正确输出y值之间的偏差。比如计算\(h-y\)^2,当得到的值比较大时，就说明我们的神经网络的输出与预期的正确输出偏差较大，反之，如果得到的值很小甚至等于0，就说明我们的模型工作的不错，能够正确的预测输出值。

##### 2.2.3 二次损失函数（quadratic loss function）

和名字一样，quadratic loss function 通过计算h和y之间差值的二次方来表达一个神经网络效果。具体的表现形式如下:  
`J(ø)=(h(ø,X)-Y)^2`  
这个公式几乎就是上面提到的\(h-y\)^2,其中希腊字母ø\(theta\)代表网络中所有的参数，X是神经网络的输入数据，Y是预期输出数据，与X相对应。

**为何ø作为网络参数却加入了自变量?**

其实在这里theta才是自变量，因为一开始无法确定让网络正确工作的参数值是多少，而学习算法learn通过某种策略，通过不断更新参数值theta使得**损失函数J\(ø,X,Y\)**的值变小。theta是一个**不断变化的量**

### 2.3 梯度下降算法

##### 2.3.1

梯度下降算法用于帮助见效损失函数的值

![](/assets/梯度下降.png)

如图所示，随即初始化的网络参数A在这个位置，显然我们aim to使A尽量靠近B\(minimum point\)，这样才可以最小化损失函数。

“备注：上图这种函数图像向下突出的函数被称为凸函数，**此处注意记忆，凸指的是向下凸**“

##### 2.3.2什么是“梯度”

梯度本身是一个向量，由损失函数对每个自变量（图中的thera0和theta1）分别求偏导（见前章）。  
简单点说，梯度指向损失函数变化最快的那个方向（且该方向让函数值变大），对于上图中3D就是在曲面上最陡峭的方向\(即A的方向\)对于2D的situation, 其实就是斜率的方向.

抽象理解：梯度即为函数所有方向导数中绝对值最大的方向

##### 2.3.3 梯度下降算法

为了使A向B点移动，就可以对A的值减去该点的梯度，用公式表达就是`ø=ø=∂*J'(ø)`这里多了一个alpha，因为梯度只为我们指明了更新参数theta的方向，而具体沿着这个方向走多远则由alpha控制。

当走到next position后，再求该点的梯度，用梯度更新参数的位置，如此重复，直到逼近B点。**这就是梯度下降算法的原理**

"备注：alpha在这里被称为-**超参数\(hyper parameter\)**"

### 2.4 参数\(parameter\)与超参数\(hyper parameter\)

### 2.5 Summary 总结：

> 作为第一次实验，我们讲到的概念和基础理论比较多，你可能需要较多的时间才能消化。如果你暂时无法理解其中的一些概念，不要气馁，请回去重新看一下，思考一下。当后面再用到这些东西而你觉得映像模糊时，也请重新回过头来看一下。只要你能理解这些基本的东西，可以说，后面的学习都会势如破竹。你将从此走进深度学习的世界！
>
> 本次实验，我们学到的知识有：
>
> 1. 机器学习（包括深度学习）利用训练数据`data`，使用学习算法`learn`对模型`model`中包含的参数进行更新。使得评价模型效果的`损失函数`不断减小并达到最优值。
> 2. 深度学习中的模型一般是指`(深度)神经网络`，`神经网络`由多个网络层构成，层与层之间通过连接来传递信息。
> 3. 神经网络中一般包含线性运算和非线性运算（激活函数）部分，两个线性运算部分之间必须存在非线性部分，否则这两个线性部分会合并成一个线性部分。
> 4. 损失函数用来描述一个神经网络模型的性能，损失函数值越小模型性能越好。
> 5. 梯度下降算法可以通过多次迭代更新模型参数值来使损失函数值减小。梯度下降算法的关键是求损失函数对于网络参数的梯度。
> 6. 机器学习（包括深度学习）分为有监督学习和无监督学习，前者的训练数据既包括输入，也包括输入对应的正确输出（标签`label`）。后者的训练数据不包含正确输出。
> 7. 机器学习解决的问题一般可以分为回归问题、分类问题、聚类问题这三种（实际上还有别的种类），本课程主要研究分类问题。
> 8. 超参数是在训练模型的过程中，为了得到最优模型参数而手工设置的一类参数。设置合理的超参数值，对模型参数的优化十分重要。

### 2.6 shiyanlou.com 中留的课后作业

由于无正确答案，答案并不一定正确，如果有人看到这里觉得我的答案有错误，务必拜托您指正.

1. 一个如本次实验所描述的神经网络有两层，第一层有10个神经元，第二层有20个神经元，请问这两层神经元之间有多少条连接？第一层到第二层之间由这些连接所表示的线性变换矩阵尺寸是多少？
   1. 有200条连接
   2. 表示的变换尺寸是20x10
2. “使用深度学习预测股票走势曲线”是分类问题还是回归问题？
   1. 不了解股票运行机制，猜测是回归问题，即输入一个x值，预测其输出值y
3. “根据人脸图片识别人的性别”是分类问题还是回归问题？
   1. 分类问题
4. 如果说，有监督学习的训练数据`data`由输入`X`和正确答案`Y`组成，那无监督学习的训练数据应该是什么样?  
   1. 无监督学习数据应只有x，

5. \[选做题\]sigmoid函数对x求导结果是什么？  
   1. ![](/assets/der_sigmoid.png)

6. \[选做题\]2.6.1小节中的图片里，为什么“学习速率适中”图中每次更新的“步子”越来越短，而“学习速率过大”图中每次更新的“步子”越来越长？

7. \[选做题\]你能自己想出一种求损失函数梯度的方法吗？
8. “手工编程计算圆的面积”中，3.14是“参数”还是“超参数”？

   1. 参数



